\chapter{Conclusion}\label{Conclusion}
% \addcontentsline{toc}{chapter}{Conclusion}

In this thesis, we considered a zero-sum strategy game of Quoridor and implemented various AI agents for the game. The main focus of our work was to create a generic interface based implementation for the game such that the agents could be seamlessly used for other games as well, and perform experiments on the game of Quoridor to show how to find the ideal parameters for the Minimax and the Monte Carlo Tree Search algorithm.

In Chapter \ref{GameDescription}, we formalized the notations for the game including the cells of the game board, movements and wall placements and using them, we formally described the rules of the game. Additionally, we also proposed an improvement upon the notation for wall placement to remove the ambiguity on the notations used in the current literature.

In Chapter \ref{relatedworks}, we performed a literature survey of \gls{AI} implementation of Quoridor. In the Chapter, we also acknowledged the sources that we considered as an inspiration for our thesis. 

In Chapter \ref{GameAnalysis}, we described the game tree of the game Quoridor. We provided metrics to quantify the complexity of the game in terms of state space and game tree complexity. During our analysis, we determined that the state space complexity increases exponentially as a function of the board dimension and is dominated by the complexity of wall placement. We also approximated the game tree complexity in terms of average branching factor and the average depth. Finally, we compared the complexities against other popular games such as Tic-tac-toe, Chess, Go and Connect-Four and determined Quoridor of dimension 3 has a complexity comparable to that of Tic-tac-toe, Quoridor of dimension 9 has complexity comparable to Chess.

In Chapter \ref{background}, we explained the background and the algorithm behind the AI agents implemented in this thesis including the minimax algorithm with alpha-beta pruning and parallel implementation, \gls{MCTS} algorithm and the A-star algorithm.

In Chapter \ref{Implementation}, we explained our implementation of the interfaces which are the fundamental part of our work. Further, we explained the various agents that we have implemented including the minimax agent, Monte-Carlo agent and A-star agent for Quoridor using the interfaces. We further illustrated with an example of another strategy game Tic-tac-toe how the interfaces could be seamlessly integrated as agents for other games as well. 

Finally in Chapter \ref{Experiments}, we presented the numerical simulations of our game considering various aforementioned agents. We simulated for the time complexity per move as a metric of quantifying the complexity of the game for different agents and the results of the agents playing against each other with varying board dimensions. From the tournament, we showed that as we increase the board dimension, the more strategical agents such as the minimax and the MCTS win almost all of their games against more simpler agents such as random, semi-random and A-star.