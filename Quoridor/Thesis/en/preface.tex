\chapter{Introduction}

In recent years, \gls{AI} is becoming an integral part of many elements of modern world including gaming \citep{Skinner2010Artificial}, pushing the boundaries of what's achievable in both single and multiplayer gaming experiences. \gls{AI}-driven games now offer users the opportunity to hone and enhance their skills, providing varying difficulty levels and offering optimal moves to guide players through each step if desired. \gls{AI} has also taken a center stage in gaming with its remarkable accomplishments in age-old strategy games such as Chess, Go, and many others. 

% . In fact, in the recent years, it has become an the main point of evolution and revolution in many of the technologies and industries. From assisted or autonomous driving \citep{Ma2020Artificial}, chat bots \citep{Wu2023ABrief} to gaming \citep{Skinner2010Artificial}, it has been a major revelation in evolving the existing technologies to generating new industry space with the plethora of new use cases.   
% 

Strategy games are a genre of gaming that require planning, often involving various tactics, decision making and execution under various resource constraints. Some examples of strategy games include Chess, Go, Shogi, Starcraft and Quoridor. They are unique compared to other genres as they require a selection of an optimal move among multiple possible moves based on a certain strategy. In many scenarios, the number of possible moves depends on the game tree, simulation and prediction of the player's and the opponent's moves, all while managing resources efficiently.

\gls{AI}, due to its suitability of solving complex decision making problems factoring in multiple variable and constraints, has been particularly effective in playing the strategy games. The history of \gls{AI} in strategy gaming dates few decades. One of the oldest marked impact of \gls{AI} in the strategy gaming came in 1997 when IBM's Deep Blue \citep{Campbell2002Deep} defeated World Chess Champion Garry Kasparov. The influence was more prominent with the success of \gls{AI} on \gls{RTS} games such as Warcraft and StarCraft \citep{Robertson2014Review} and strategy games such as Go \citep{Huang2011Monte}. Recently, DeepMind's Alpha Go for Go, Alpha Zero for Chess \citep{Silver2017Mastering} and AlphaStar for StarCraft \citep{Team2019Alphastar} have widened the gap between the \gls{AI} and human intelligence even further.

In this thesis, we have chosen Quoridor as the startegy game to analyse and implement an agent of. Designed by Mirko Marchesi, Quoridor stands out as an engaging strategic board game that is played between two or four players. The game is played on a square grid board where the objective of this game is for each player to move their pawn to the opposite side of the board. This game introduces a fascinating twist where a player, in addition to trying to move their pawn through the square grid, additionally has an option to place walls on the grid locations strategically to obstruct the opponent's path. This strategy compels the player to think of their traversal strategy while predicting the opponents strategy as well. Despite its seemingly simple rules, Quoridor demands a unique blend of strategic foresight and the ability to anticipate the moves of opponents and outmaneuver the opponent.


\section{AI algorithms}
In this section, we give a brief overview of different \gls{AI} techniques that have been considered in this thesis.

\subsection{Minimax algorithm}
Minimax algorithm, first proven by John von Neumann in 1928 in his paper \textit{Zur Theorie Der Gesellschaftsspiele} \citep{v1928theorie}, is a very popular algorithm employed in many decision-making scenarios for e.g., in decision theory, game theory and even philosophy. As suggested by the name minimax, the idea of the algorithm is to minimize the player's loss when the opponent makes a decision that gives the player the maximum loss. This algorithm has been implemented in many multi-player strategy games such as tic-tac-toe \citep{savelli2008tic}. 

The minimax algorithm involves in the player performing an exhaustive search on the game tree to determine a sequence of maximizing and minimizing moves. The complexity of such algorithm in large game tree often means such search is often impossible due to limited computational resources. To limit this complexity, further techniques such as depth-limited minimax, alpha-beta pruning and parallel minimax algorithm can be used.

\subsection{Monte-Carlo Tree Search}
\gls{MCTS} \citep{Coulom2006Efficient} is a heuristic tree search algorithm popular in decision-making processes, mostly popular in strategic games where the game tree space is too large to traverse. One problem with the minimax algorithm is that it requires a robust and accurate evaluation function to evaluate a given position in the game. This problem can be even more relevant when the game tree space is too large making it difficult to find the evaluation of a position. The basic idea of the \gls{MCTS} algorithm is that is narrows down on certain areas of the game tree, such that the exhaustive traversal and search of the tree is not required. The algorithm achieves this by taking random samples in the tree space and building a search tree based on it.

\subsection{A-star algorithm}
A star is a popular algorithm \citep{Hart1968AFormal} used mainly for graph search and traversal problems. The main aim of the A-star algorithm is to find a path between a starting node and an destination node with the least cost. The cost function of the algorithm comprises of two components, the distance from the starting node to the current node and the estimated heuristic from the current node to the destination node. As the distance to the destination node may not be exactly known, one may use the estimate such as Manhattan distance and Euclidean distance.


\section {Related Works}

Compared to some other strategy games such as Chess and Go, Quoridor has not been extensively studied in the literature. In \citep{Glendenning2002MasteringQ}, the author developed an agent for playing Quoridor using genetic algorithm to optimize the weights. The authors in \citep{Mertens2006Quoridor} study the complexity of the algorithm also develop a Quoridor playing agent based on Minimax algorithm. Likewise, the authors in \citep{Brenner2015Artificial} developed an \gls{MCTS} approach for Quoridor. Recently, in \citep{Iwanaga2022Analysis}, the authors performed an analysis of the game for a miniature 5 by 5 board.

For this thesis, we consider the following work as our inspiration:

\begin{itemize}
    \item \textbf{Mastering Quoridor \citep{Glendenning2002MasteringQ}}
    The author of the thesis implements and assesses various algorithms like Negamax, Alpha-beta Negamax among others. Additionally, they utilized a genetic algorithm to refine the weights within a linear weighted evaluation function, employing 10 distinct features suggested by the author, some of which include player's position towards their goal side, the opponent's position towards their respective goal, the remaining count of walls available to the player, etc.
\end{itemize}

In sharp contrast to the aforementioned works, our thesis takes a distinctly different path by delving deeply into the architectural aspects of AI. Our approach emphasizes abstraction to the greatest extent possible, with an eye on facilitating seamless integration into a broad spectrum of games. We prioritize creating an interface that is adaptable to diverse game environments, setting our research apart from the game-specific focus of the prior works.


\section{Thesis Outline}

The objective of this thesis is to construct a well-structured framework and user-friendly interfaces that seamlessly integrates AI algorithms into the Quoridor game. The development of AI algorithms customized to Quoridor's rule set will not only enhance our understanding of the game's intricate nuances but also facilitate the creation of an intuitive interface for simulating these AI agents. Furthermore, a comprehensive evaluation will be conducted to identify the top-performing AI agent among a set of implemented AI agents including the minimax agent, \gls{MCTS} agent and the A-star agent. In addition to this, the project will encompass the creation of a user-friendly interface that empowers players to engage with an AI opponent of their choice, thereby bolstering the game's accessibility and inclusivity.

The structure of this thesis is as follows. In chapter \ref{GameDescription}, we will introduce the formal notations of the game and based on it, formally explain the rules of the game. In chapter \ref{GameAnalysis}, we will perform a game analsis from the perspective of game complexity including the state-space complexity and the game tree complexity. In chapter \ref{Implementation}, we will explain the implementation of the game interface and the AI agents. In chapter \ref{Experiments}, we will simulate the results of the game between the implemented AI agents and finally conclude the thesis in chapter \ref{Conclusion}.


